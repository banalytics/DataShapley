{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from Shapley import ShapNN\n",
        "from DShap import DShap\n",
        "from shap_utils import *\n",
        "%matplotlib inline\n",
        "MEM_DIR \u003d \u0027./\u0027"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Let\u0027s have a calssification problem and use the a losigitic regression model for a small data set of size 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "problem, model \u003d \u0027classification\u0027, \u0027logistic\u0027\n",
        "hidden_units \u003d [] # Empty list in the case of logistic regression.\n",
        "train_size \u003d 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Create Synthetic Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Let\u0027s create a synthetic data set with input-output $y \u003d Bernouli(f(x))$ where $f$ is a polynomial of oder \u0027difficulty\u0027 and $x \\in \\mathscr{R}^d$. (\u0027important_dims\u0027 determines the number of $d$ dimensions in $x$ that are non-null)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "d, difficulty \u003d 50, 1\n",
        "num_classes \u003d 2\n",
        "tol \u003d 0.03\n",
        "target_accuracy \u003d 0.7\n",
        "important_dims \u003d 5\n",
        "clf \u003d return_model(model, solver\u003d\u0027liblinear\u0027, hidden_units\u003dtuple(hidden_units))\n",
        "_param \u003d 1.0\n",
        "for _ in range(100):\n",
        "    X_raw \u003d np.random.multivariate_normal(mean\u003dnp.zeros(d), cov \u003d np.eye(d), \n",
        "                                          size\u003dtrain_size + 5000)\n",
        "    _, y_raw, _, _ \u003d label_generator(\n",
        "        problem, X_raw, param \u003d _param,  difficulty \u003d difficulty, important\u003dimportant_dims)\n",
        "    clf.fit(X_raw[:train_size], y_raw[:train_size])\n",
        "    test_acc \u003d clf.score(X_raw[train_size:], y_raw[train_size:])\n",
        "    if test_acc\u003etarget_accuracy:\n",
        "        break\n",
        "    _param *\u003d 1.1\n",
        "print(\u0027Performance using the whole training set \u003d {0:.2f}\u0027.format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Running"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Now let\u0027s create the instance that takes cares of computing all the algorithms for the data set. Here we run it several times one-after-another, but in a real-world scenario they could be run in parallel. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "X, y \u003d X_raw[:train_size], y_raw[:train_size]\nX_test, y_test \u003d X_raw[train_size:], y_raw[train_size:]\nmodel \u003d \u0027logistic\u0027\nproblem \u003d \u0027classification\u0027\nnum_test \u003d 1000\ndirectory \u003d \u0027./temp\u0027\ndshap \u003d DShap(\n    X, \n    y, \n    X_test, \n    y_test, \n    num_test, \n    sources\u003dsources, \n    model_family\u003dmodel, \n    metric\u003d{\u0027metric\u0027: \u0027accuracy\u0027, \u0027arguments\u0027: {}},\n    directory\u003ddirectory, seed\u003d0)\ndshap.run(100, 0.1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "X, y \u003d X_raw[:100], y_raw[:100]\nX_test, y_test \u003d X_raw[100:], y_raw[100:]\nmodel \u003d \u0027logistic\u0027\nproblem \u003d \u0027classification\u0027\nnum_test \u003d 1000\ndirectory \u003d \u0027./temp\u0027\ndshap \u003d DShap(X, y, X_test, y_test, num_test, model_family\u003dmodel, metric\u003d{\u0027metric\u0027: \u0027accuracy\u0027, \u0027arguments\u0027: {}},\n              directory\u003ddirectory, seed\u003d1)\ndshap.run(100, 0.1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "X, y \u003d X_raw[:100], y_raw[:100]\nX_test, y_test \u003d X_raw[100:], y_raw[100:]\nmodel \u003d \u0027logistic\u0027\nproblem \u003d \u0027classification\u0027\nnum_test \u003d 1000\ndirectory \u003d \u0027./temp\u0027\ndshap \u003d DShap(X, y, X_test, y_test, num_test, model_family\u003dmodel, metric\u003d{\u0027metric\u0027: \u0027accuracy\u0027, \u0027arguments\u0027: {}},\n              directory\u003ddirectory, seed\u003d2)\ndshap.run(100, 0.1)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Now we merge results for the parallel runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "dshap.merge_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Let\u0027s look at the convergence plots of the algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "convergence_plots(dshap.marginals_tmc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "convergence_plots(dshap.marginals_g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Now let\u0027s see the effect of removing high valuen points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "dshap.performance_plots([dshap.vals_tmc, dshap.vals_g, dshap.vals_loo], num_plot_markers\u003d20,\n",
        "                       sources\u003ddshap.sources)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}